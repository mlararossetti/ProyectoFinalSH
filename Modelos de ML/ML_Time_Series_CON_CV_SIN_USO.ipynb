{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import generate_cutoffs, cross_validation, performance_metrics\n",
    "from prophet.plot import plot_plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ce carga un subdataset con los datos necesarios para el modelo de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv(r\"..\\datasets\\2. Depurados\\TLC Aggregated Data\\ML_TS_Input.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el valor máximo de la columna 'date'\n",
    "max_date = df['date'].max()\n",
    "# Calcular la fecha de diciembre dentro de 5 años\n",
    "future_date = datetime(max_date.year + 5, 12, 1)\n",
    "# Calcular la cantidad de meses entre ambas fechas\n",
    "months_difference = (future_date.year - max_date.year) * 12 + (future_date.month - max_date.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para guardar el forecast en un archivo CSV\n",
    "def guardar_predicciones(forecast, nombre_archivo=\"predicciones.csv\"):\n",
    "    try:\n",
    "        forecast.to_csv(nombre_archivo, index=False)\n",
    "        print(f\"Predicciones guardadas en {nombre_archivo}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar las predicciones: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definir parámetros de selección para la industria y la columna\n",
    "# industry_type = input(f\"Seleccione el tipo de industria para predecir {tuple(df['industry'].unique())}: \")\n",
    "# column_name = input(f\"Seleccione la variable que desea predecir ('total_trips','unique_vehicles','avg_hours_per_day_per_driver', 'total_amount', 'total_co2_emission'): \")\n",
    "\n",
    "# # Selección de períodos y frecuencia para predicción\n",
    "# periodos = int(input(f\"La cantidad de meses entre {max_date.strftime('%Y-%m-%d')} y diciembre dentro de 5 años es: {months_difference} meses.\"\n",
    "#                         \"Seleccione la cantidad de períodos para la predicción: \"))\n",
    "# frecuencia = \"M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_original(df_prophet, column_name):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df_prophet[\"ds\"], y=df_prophet[\"y\"], marker=dict(symbol='circle', color='royalblue')))\n",
    "    fig.layout.update(title_text=\"Datos históricos\", yaxis_title=f\"{column_name}\", xaxis_rangeslider_visible=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_predicción(df_prophet, column_name, forecast,industry_type):\n",
    "            \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df_prophet[\"ds\"], y=df_prophet[\"y\"], name='Datos Históricos', marker=dict(symbol='circle', color='royalblue')))\n",
    "    fig.add_trace(go.Scatter(x=forecast['ds'], y=forecast['yhat'], name='Predicción', marker=dict(symbol='diamond', color='yellow')))\n",
    "    fig.add_trace(go.Scatter(x=forecast['ds'].tolist() + forecast['ds'][::-1].tolist(), \n",
    "                                y=forecast['yhat_upper'].tolist() + forecast['yhat_lower'][::-1].tolist(), \n",
    "                                fill='toself', fillcolor='rgba(255, 255, 255, 0.2)', \n",
    "                                line=dict(color='rgba(255, 255, 255, 0)'), name='Intervalo de predicción'))\n",
    "    fig.layout.update(xaxis_title='Fecha', yaxis_title=column_name, title_text=f\"Predicción para {column_name} ({industry_type})\", \n",
    "                        xaxis_rangeslider_visible=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis para cada variable y cada industria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de períodos y frecuencia para predicción\n",
    "industry_types = df['industry'].unique()\n",
    "columns_to_predict = ['total_trips', 'unique_vehicles', 'avg_hours_per_day_per_driver', 'total_amount', 'total_co2_emission']\n",
    "periodos = 64\n",
    "frecuencia = \"M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>industry</th>\n",
       "      <th>total_trips</th>\n",
       "      <th>unique_vehicles</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>avg_trip_distance</th>\n",
       "      <th>avg_hours_per_day_per_driver</th>\n",
       "      <th>total_co2_emission</th>\n",
       "      <th>days_in_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>FHV - High Volume</td>\n",
       "      <td>11902481</td>\n",
       "      <td>47594</td>\n",
       "      <td>1.917688e+08</td>\n",
       "      <td>3.64</td>\n",
       "      <td>6.800</td>\n",
       "      <td>17332.2978</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>FHV - Other</td>\n",
       "      <td>1142350</td>\n",
       "      <td>10128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.800</td>\n",
       "      <td>1660.0704</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Green Taxi</td>\n",
       "      <td>76477</td>\n",
       "      <td>982</td>\n",
       "      <td>1.748679e+06</td>\n",
       "      <td>3.46</td>\n",
       "      <td>4.000</td>\n",
       "      <td>105.8211</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Total Mercado</td>\n",
       "      <td>14486920</td>\n",
       "      <td>63329</td>\n",
       "      <td>2.148706e+08</td>\n",
       "      <td>3.29</td>\n",
       "      <td>5.475</td>\n",
       "      <td>20424.6565</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Yellow Taxi</td>\n",
       "      <td>1365612</td>\n",
       "      <td>4625</td>\n",
       "      <td>2.135305e+07</td>\n",
       "      <td>2.43</td>\n",
       "      <td>7.300</td>\n",
       "      <td>1326.4672</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date           industry  total_trips  unique_vehicles  total_amount  \\\n",
       "0 2021-01-01  FHV - High Volume     11902481            47594  1.917688e+08   \n",
       "1 2021-01-01        FHV - Other      1142350            10128           NaN   \n",
       "2 2021-01-01         Green Taxi        76477              982  1.748679e+06   \n",
       "3 2021-01-01      Total Mercado     14486920            63329  2.148706e+08   \n",
       "4 2021-01-01        Yellow Taxi      1365612             4625  2.135305e+07   \n",
       "\n",
       "   avg_trip_distance  avg_hours_per_day_per_driver  total_co2_emission  \\\n",
       "0               3.64                         6.800          17332.2978   \n",
       "1               3.63                         3.800           1660.0704   \n",
       "2               3.46                         4.000            105.8211   \n",
       "3               3.29                         5.475          20424.6565   \n",
       "4               2.43                         7.300           1326.4672   \n",
       "\n",
       "   days_in_month  \n",
       "0             31  \n",
       "1             31  \n",
       "2             31  \n",
       "3             31  \n",
       "4             31  "
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar los datos y filtrar la serie de tiempo seleccionada\n",
    "def cargar_y_preparar_datos(df, industry_type, column_name):\n",
    "    \"\"\"\n",
    "    Filtra y prepara los datos para Prophet según el tipo de industria y la columna seleccionada.\n",
    "    \"\"\"\n",
    "    df_filtered = df[df['industry'] == industry_type][['date', column_name]].copy()\n",
    "    df_filtered.columns = ['ds', 'y']  # Renombrar columnas para Prophet\n",
    "    df_filtered['ds'] = pd.to_datetime(df_filtered['ds'])  # Asegurar formato de fecha\n",
    "    return df_filtered if not df_filtered['y'].isnull().all() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, periodos, frecuencia):\n",
    "    # Configuración de validación cruzada\n",
    "\n",
    "    # This cross validation procedure can be done automatically for a range of historical cutoffs using the cross_validation function.\n",
    "    # We specify the forecast horizon (horizon), and then optionally the size of the initial training period (initial) and the spacing\n",
    "    # between cutoff dates (period). By default, the initial training period is set to three times the horizon, and cutoffs are made every half a horizon.\n",
    "    # Dado que el set de datos tiene únicamente 44 meses de historia, no se puede aplicar cross validation con la cantidad de períodos necesarios (64),\n",
    "    # por este motivo, se realiza el ajuste con 12 meses de pronóstico y 24 para el período de entrenamiento.\n",
    "\n",
    "    initial = f\"{24 * 30.4} days\"  # 24 meses aproximados en días\n",
    "    period = f\"{30.4} days\"        # Un mes aproximado en días\n",
    "    horizon = f\"{12 * 30.4} days\"  # Horizonte basado en la entrada\n",
    "\n",
    "    # Validación cruzada\n",
    "    df_cv = cross_validation(\n",
    "        model,\n",
    "        initial=initial,\n",
    "        period=period,\n",
    "        horizon=horizon\n",
    "    )\n",
    "    \n",
    "    # Extraer valores reales y predichos\n",
    "    y_true = df_cv['y'].values\n",
    "    y_pred = df_cv['yhat'].values\n",
    "\n",
    "    # Calcular métricas\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    smape = 100 / len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "    \n",
    "    print(\"Resultados de validación cruzada:\")    \n",
    "    print(f'Mean Absolute Error: {mae:.2f}')\n",
    "    print(f'Mean Absolute Percentage Error : {mape:.2f}')\n",
    "    print(f'Symmetric Mean Absolute Percentage Errorr : {smape:.2f}')\n",
    "    print(f'Mean Squared Error: {mse:.2f}')\n",
    "    print(f'Root Mean Squared Error: {rmse:.2f}')\n",
    "\n",
    "    return {'mae': mae, 'mape': mape, 'smape': smape, 'mse': mse, 'rmse': rmse}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronóstico_con_grid_search(df_prophet, periodos, frecuencia):\n",
    "    \"\"\"\n",
    "    Realiza Grid Search para encontrar los mejores hiperparámetros de Prophet y calcula el error.\n",
    "    \"\"\"\n",
    "\n",
    "    grid_search = {\n",
    "        'changepoint_prior_scale': [0.01, 0.1, 0.5],\n",
    "        'seasonality_prior_scale': [5.0, 10.0, 20.0],\n",
    "        'seasonality_mode': ['additive', 'multiplicative'],\n",
    "        'fourier_order': [5, 10, 20]\n",
    "    }\n",
    "    \n",
    "    best_params = None\n",
    "    best_error = float('inf')\n",
    "    resultados = []\n",
    "    \n",
    "    # Grid Search\n",
    "    for cps in grid_search['changepoint_prior_scale']:\n",
    "        for sps in grid_search['seasonality_prior_scale']:\n",
    "            for sm in grid_search['seasonality_mode']:\n",
    "                for fo in grid_search['fourier_order']:\n",
    "                      \n",
    "                        print(f\"Evaluanco combinación: CPS={cps}, SPS={sps}, SM={sm}, FO={fo}\")\n",
    "                        \n",
    "                        # Crear y entrenar modelo Prophet con los parámetros actuales\n",
    "                        model = Prophet(changepoint_prior_scale=cps, seasonality_prior_scale=sps, seasonality_mode=sm)\n",
    "                        model = Prophet(weekly_seasonality=False)\n",
    "                        model.add_seasonality(name='monthly', period=12, fourier_order=fo)\n",
    "                        model.fit(df_prophet)\n",
    "\n",
    "                        # Evaluar modelo\n",
    "                        metrics = evaluate_model(model, periodos, frecuencia)\n",
    "                        if metrics is None:\n",
    "                            continue\n",
    "\n",
    "                        resultados.append({\n",
    "                            'changepoint_prior_scale': cps,\n",
    "                            'seasonality_prior_scale': sps,\n",
    "                            'seasonality_mode': sm,\n",
    "                            'fourier_order': fo,\n",
    "                            **metrics\n",
    "                        })\n",
    "\n",
    "                        # Actualizar mejores parámetros si el MAE es menor\n",
    "                        if metrics['mae'] < best_error:\n",
    "                            best_error = metrics['mae']\n",
    "                            best_params = {\n",
    "                                'changepoint_prior_scale': cps,\n",
    "                                'seasonality_prior_scale': sps,\n",
    "                                'seasonality_mode': sm,\n",
    "                                'fourier_order': fo\n",
    "                            }\n",
    "                    \n",
    "\n",
    "    return best_params, best_error, resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: FHV - High Volume, columna: total_trips\n",
      "Evaluanco combinación: CPS=0.01, SPS=5.0, SM=additive, FO=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:11:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:11:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53022c59a764e56b3f91da3a09edd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:11:25 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[526], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Ejecutar Grid Search\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m best_params, best_error, resultados \u001b[38;5;241m=\u001b[39m \u001b[43mpronóstico_con_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_prophet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiodos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrecuencia\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Guardar resultados\u001b[39;00m\n\u001b[0;32m     17\u001b[0m mejores_resultados[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindustry_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmejores_parametros\u001b[39m\u001b[38;5;124m'\u001b[39m: best_params,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmejor_error\u001b[39m\u001b[38;5;124m'\u001b[39m: best_error,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresultados_grid_search\u001b[39m\u001b[38;5;124m'\u001b[39m: resultados\n\u001b[0;32m     21\u001b[0m }\n",
      "Cell \u001b[1;32mIn[525], line 32\u001b[0m, in \u001b[0;36mpronóstico_con_grid_search\u001b[1;34m(df_prophet, periodos, frecuencia)\u001b[0m\n\u001b[0;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(df_prophet)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Evaluar modelo\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiodos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrecuencia\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[524], line 15\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, periodos, frecuencia)\u001b[0m\n\u001b[0;32m     12\u001b[0m horizon \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m12\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m30.4\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m days\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Horizonte basado en la entrada\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Validación cruzada\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhorizon\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Extraer valores reales y predichos\u001b[39;00m\n\u001b[0;32m     23\u001b[0m y_true \u001b[38;5;241m=\u001b[39m df_cv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\Hernán\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\prophet\\diagnostics.py:207\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(model, horizon, period, initial, parallel, cutoffs, disable_tqdm, extra_output_columns)\u001b[0m\n\u001b[0;32m    203\u001b[0m         predicts \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mgather(predicts)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     predicts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 207\u001b[0m         \u001b[43msingle_cutoff_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_columns\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    208\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cutoff \u001b[38;5;129;01min\u001b[39;00m (tqdm(cutoffs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m disable_tqdm \u001b[38;5;28;01melse\u001b[39;00m cutoffs)\n\u001b[0;32m    209\u001b[0m     ]\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Combine all predicted pd.DataFrame into one pd.DataFrame\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(predicts, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Hernán\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\prophet\\diagnostics.py:246\u001b[0m, in \u001b[0;36msingle_cutoff_forecast\u001b[1;34m(df, model, cutoff, horizon, predict_columns)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m history_c\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLess than two datapoints before cutoff. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncrease initial window.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    245\u001b[0m     )\n\u001b[1;32m--> 246\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Calculate yhat\u001b[39;00m\n\u001b[0;32m    248\u001b[0m index_predicted \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m cutoff) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m cutoff \u001b[38;5;241m+\u001b[39m horizon)\n",
      "File \u001b[1;32mc:\\Users\\Hernán\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\prophet\\forecaster.py:1232\u001b[0m, in \u001b[0;36mProphet.fit\u001b[1;34m(self, df, **kwargs)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39msampling(stan_init, dat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmcmc_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstan_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstan_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_backend\u001b[38;5;241m.\u001b[39mstan_fit\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;66;03m# If no changepoints were requested, replace delta with 0s\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hernán\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\prophet\\models.py:121\u001b[0m, in \u001b[0;36mCmdStanPyBackend.fit\u001b[1;34m(self, stan_init, stan_data, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstan_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# Fall back on Newton\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewton_fallback \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNewton\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Hernán\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\cmdstanpy\\model.py:644\u001b[0m, in \u001b[0;36mCmdStanModel.optimize\u001b[1;34m(self, data, seed, inits, output_dir, sig_figs, save_profile, algorithm, init_alpha, tol_obj, tol_rel_obj, tol_grad, tol_rel_grad, tol_param, history_size, iter, save_iterations, require_converged, show_console, refresh, time_fmt, timeout, jacobian)\u001b[0m\n\u001b[0;32m    642\u001b[0m     dummy_chain_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    643\u001b[0m     runset \u001b[38;5;241m=\u001b[39m RunSet(args\u001b[38;5;241m=\u001b[39margs, chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, time_fmt\u001b[38;5;241m=\u001b[39mtime_fmt)\n\u001b[1;32m--> 644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_cmdstan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrunset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_chain_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_console\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_console\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    650\u001b[0m runset\u001b[38;5;241m.\u001b[39mraise_for_timeouts()\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runset\u001b[38;5;241m.\u001b[39m_check_retcodes():\n",
      "File \u001b[1;32mc:\\Users\\Hernán\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\cmdstanpy\\model.py:2087\u001b[0m, in \u001b[0;36mCmdStanModel._run_cmdstan\u001b[1;34m(self, runset, idx, show_progress, show_console, progress_hook, timeout)\u001b[0m\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2086\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2087\u001b[0m         line \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2088\u001b[0m         fd_out\u001b[38;5;241m.\u001b[39mwrite(line)\n\u001b[0;32m   2089\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\Hernán\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py:22\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalDecoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalDecoder):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,decoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterar sobre todas las combinaciones de industria y columna\n",
    "BANDERA = True\n",
    "mejores_resultados = {}\n",
    "for industry_type in industry_types:\n",
    "    for column_name in columns_to_predict:\n",
    "        # Preparar los datos\n",
    "        df_prophet = cargar_y_preparar_datos(df, industry_type, column_name)\n",
    "        if BANDERA == True:\n",
    "            if df_prophet is not None and not df_prophet.empty and df_prophet['y'].notnull().all():\n",
    "                print(f\"Procesando: {industry_type}, columna: {column_name}\")\n",
    "                start_time = time.time()\n",
    "\n",
    "                # Ejecutar Grid Search\n",
    "                best_params, best_error, resultados = pronóstico_con_grid_search(df_prophet, periodos=12, frecuencia='M')\n",
    "                \n",
    "                # Guardar resultados\n",
    "                mejores_resultados[f\"{industry_type}_{column_name}\"] = {\n",
    "                    'mejores_parametros': best_params,\n",
    "                    'mejor_error': best_error,\n",
    "                    'resultados_grid_search': resultados\n",
    "                }\n",
    "                    \n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"Tiempo para {industry_type}, {column_name}: {elapsed_time:.2f} segundos\")\n",
    "                BANDERA = False\n",
    "\n",
    "\n",
    "# Mostrar los mejores parámetros por combinación\n",
    "for key, value in mejores_resultados.items():\n",
    "    print(f\"Industria y columna: {key}\")\n",
    "    print(f\"Mejores parámetros: {value['mejores_parametros']}\")\n",
    "    print(f\"Mejor error (MAE): {value['mejor_error']}\\n\")\n",
    "\n",
    "    # Mostrar los primeros resultados del Grid Search\n",
    "    print(value['resultados_grid_search'].head())\n",
    "\n",
    "\n",
    "resumen_resultados = pd.DataFrame([\n",
    "    {'industria_columna': key, **value['mejores_parametros'], 'mejor_error': value['mejor_error']}\n",
    "    for key, value in mejores_resultados.items()\n",
    "])\n",
    "resumen_resultados.to_csv(\"resumen_mejores_resultados.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
